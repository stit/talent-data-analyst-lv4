{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eec3119",
   "metadata": {},
   "source": [
    "# ST IT Cloud - Data and Analytics Test LV.4\n",
    "\n",
    "Esse teste deve avaliar alguns conceitos de big data e a qualidade técnica na manipulacão de dados, otimização de performance, trabalho com arquivos grandes e tratamento de qualidade.\n",
    "\n",
    "## Passo a passo\n",
    "\n",
    "- *Parte teórica:* responda as questões abaixo preenchendo as células em branco.\n",
    "- *Parte prática:* disponibilizamos aqui 2 cases para, leia os enunciados dos problemas, desenvolver os programas, utilizando a **stack definida durante o processo seletivo**, para entregar os dados de acordo com os requisitos descritos abaixo.\n",
    "\n",
    "\n",
    "\n",
    "**Faz parte dos critérios de avaliacão a pontualidade da entrega. Implemente até onde for possível dentro do prazo acordado.**\n",
    "\n",
    "**Os dados de pessoas foram gerados de forma aleatória, utilizando a biblioteca FakerJS, FakerJS-BR e Faker**\n",
    "\n",
    "LEMBRE-SE: A entrega deve conter TODOS os passos para o avaliador executar o programa (keep it simple).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9447dec4",
   "metadata": {},
   "source": [
    "**Questão 1** - Descreva de forma detalhada quais são as etapas na construção de um pipeline de dados, sem considerar ferramentas específicas, imagine que é seu primeiro contato com o cliente e você precisa entender a demanda dele e explicar quais são os passos que você terá que implementar para entregar a demanda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11c64a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_16624/523853122.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\fpurc\\AppData\\Local\\Temp/ipykernel_16624/523853122.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    1- Entendimento da necessidade do cliente\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "1- Entendimento da necessidade do cliente\n",
    "2- Verificar qual sera o formato de fonte com os dados vindo do cliente\n",
    "3- Desenhar a melhor arquitetura para a requisicao dos dados, escolher melhor metodo para fazer a ingestao dos dados\n",
    "4- criar um pipeline de preparation de dados \n",
    "5- separar os dados em camadas\n",
    "6- disponibilizar os dados conforme as regras para analises futuras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc703af3",
   "metadata": {},
   "source": [
    "**Questão 2** - Defina com suas palavras um processamento em streaming e processamento em batch. Qual sua experiência com cada uma delas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028a8db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "1- processamento em batch quando falamos de volumes grandes de dados, ou onde as fontes de dados vem de sistemas legados e é neceessário que seja armazenado para ser processado. \n",
    "2- para um processamento de volumes mais rapido e para disponibilizar analises em movimento, \"nearrealtime\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1c3f10",
   "metadata": {},
   "source": [
    "**Questão 3** - Quais são as camadas de um Data Lake?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b803419",
   "metadata": {},
   "outputs": [],
   "source": [
    "1- staging\n",
    "2- raw \n",
    "3- work ou common \n",
    "4- curated ou businness view "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62477089",
   "metadata": {},
   "source": [
    "**Questão 4** - Quais as diferenças de um Data Lake e um DW?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f897c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DW - tem uma organizacao de dados por assunto, geralmente seguindo algum tipo de metodologia starschema ou snowflake. Sao criados pequenos armazens de dados.\n",
    "Data Lake - Lugar onde sao armazenados os dados em seu formato bruto para que depois sejam separados em camadas e aplicado regras de negocio conforme a necessidade do cliente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7099a05e",
   "metadata": {},
   "source": [
    "**Questão 5** - O que é arquitetura Lambda e Kappa? Descreva com suas palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4347923",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nao tenho conhecimento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3d483e",
   "metadata": {},
   "source": [
    "**Questão 6** - O que é Data Quality para você e como você implementa isso nos seus processos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf54dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qualidades dos dados é garantir que a informacao que estamos recebendo esteja coerente e com acuracia para a melhor tomada de decisao\n",
    "\n",
    "- temos uma area de QA que faz a validacao de dados\n",
    "- peer review de pepiline da dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4834d6",
   "metadata": {},
   "source": [
    "**Questão 7** - Em uma escala de 0 a 10, qual seria seu nível de experiência com PySpark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ddda4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ef78ba",
   "metadata": {},
   "source": [
    "**Questão 8** - Em uma escala de 0 a 10, qual seria seu nível de experiência com SQL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33569bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5f7ee6",
   "metadata": {},
   "source": [
    "**Questão 9** - Descreva suas expeciências com banco de dados SQL e NoSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a558d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ja trabalhei com bancos ORACLE, SQL SERVER , MySQL e PostGreSQL.\n",
    "Em NoSQL trabalhei com bancu HUE e Hive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2fa6e5",
   "metadata": {},
   "source": [
    "**Questão 10** - Tem experiência com versionamento de código? Com quais ferramentas já trabalhou? Descreva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1932a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sim, uso o GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe2714f",
   "metadata": {},
   "source": [
    "**Questão 11** - Tem experiência em desenvolvimento em cloud? Se sim, especifique a(s) plataforma(s) que já trabalhou e suas principais implementações e conhecimentos em cada serviço."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47d2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sim, ja trabalhei com Azure (Databricks) e AWS\n",
    "\n",
    "AWS\n",
    "-EC2 criar instance\n",
    "-S3 Buckets \n",
    "-CloudFormation  \n",
    "-Glue  catalogo de dados\n",
    "-IAM  grupo de seguranca\n",
    "-CloudWatch\n",
    "- Athena \n",
    "\n",
    "Azure\n",
    "\n",
    "- AzureDatabricks \n",
    "-AzureSQL\n",
    "- AzureDevops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9bc70d",
   "metadata": {},
   "source": [
    "**Questão 12** - Tem experiência com metodologia ágil? Qual?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5be8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sim Scrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb61f06",
   "metadata": {},
   "source": [
    "# TESTE PRÁTICO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed8c6a5",
   "metadata": {},
   "source": [
    "**Problema 1**: Você está recebendo o arquivo 'dados_cadastrais_fake.csv' que contem dados cadastrais de clientes, mas para que análises ou relatórios sejam feitos é necessário limpar e normalizar os dados. Além disso, existe uma coluna com o número de cpf e outra com cnpj, você precisará padronizar deixando apenas dígitos em formato string (sem caracteres especiais), implementar uma forma de verificar se tais documentos são válidos sendo que a informação deve se adicionada ao dataframe em outras duas novas colunas.\n",
    "\n",
    "Após a normalização, gere reports que respondam as seguintes perguntas:\n",
    "- Quantos clientes temos nessa base?\n",
    "- Qual a média de idade dos clientes?\n",
    "- Quantos clientes nessa base pertencem a cada estado?\n",
    "- Quantos CPFs válidos e inválidos foram encontrados?\n",
    "- Quantos CNPJs válidos e inválidos foram encontrados?\n",
    "\n",
    "Ao final gere um arquivo no formato csv e um outro arquivo no formato parquet chamado (problema1_normalizado), eles serão destinados para pessoas distintas.\n",
    "\n",
    "*EXTRA:* executar as mesmas validações no *1E8.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b1b6c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nomes</th>\n",
       "      <th>idade</th>\n",
       "      <th>cidade</th>\n",
       "      <th>estado</th>\n",
       "      <th>cpf</th>\n",
       "      <th>cnpj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dennis Daniels</td>\n",
       "      <td>31</td>\n",
       "      <td>ACRELÂNDIA</td>\n",
       "      <td>AC</td>\n",
       "      <td>97566536800</td>\n",
       "      <td>06589184909526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leah Becker</td>\n",
       "      <td>42</td>\n",
       "      <td>ÁGUA BRANCA</td>\n",
       "      <td>AL</td>\n",
       "      <td>425.263.807-07</td>\n",
       "      <td>25.673.336/2350-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sally Ford</td>\n",
       "      <td>18</td>\n",
       "      <td>ALVARÃES</td>\n",
       "      <td>AM</td>\n",
       "      <td>34647754103</td>\n",
       "      <td>26543101702989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Colleen Duncan</td>\n",
       "      <td>21</td>\n",
       "      <td>SERRA DO NAVIO</td>\n",
       "      <td>AP</td>\n",
       "      <td>252.531.560-03</td>\n",
       "      <td>19.062.080/5100-98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jeff Stephenson</td>\n",
       "      <td>73</td>\n",
       "      <td>ABAÍRA</td>\n",
       "      <td>BA</td>\n",
       "      <td>49668886542</td>\n",
       "      <td>97794530015384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Rebekah Mitchell PhD</td>\n",
       "      <td>55</td>\n",
       "      <td>ABAIARA</td>\n",
       "      <td>CE</td>\n",
       "      <td>744.822.622-34</td>\n",
       "      <td>16.740.076/9329-75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Lisa Parrish Jr.</td>\n",
       "      <td>73</td>\n",
       "      <td>Brasília</td>\n",
       "      <td>DF</td>\n",
       "      <td>10683395190</td>\n",
       "      <td>32246978843482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Michael Young MD</td>\n",
       "      <td>87</td>\n",
       "      <td>AFONSO CLÁUDIO</td>\n",
       "      <td>ES</td>\n",
       "      <td>538.223.638-04</td>\n",
       "      <td>86.601.303/7580-88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Kevin Watson DDS</td>\n",
       "      <td>82</td>\n",
       "      <td>ABADIA DE GOIÁS</td>\n",
       "      <td>GO</td>\n",
       "      <td>11632512408</td>\n",
       "      <td>08651414023648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Mr. Joseph Wilson MD</td>\n",
       "      <td>50</td>\n",
       "      <td>AÇAILÂNDIA</td>\n",
       "      <td>MA</td>\n",
       "      <td>192.134.492-08</td>\n",
       "      <td>08.908.871/5161-91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nomes  idade           cidade estado             cpf  \\\n",
       "0           Dennis Daniels     31       ACRELÂNDIA     AC     97566536800   \n",
       "1              Leah Becker     42      ÁGUA BRANCA     AL  425.263.807-07   \n",
       "2               Sally Ford     18         ALVARÃES     AM     34647754103   \n",
       "3           Colleen Duncan     21   SERRA DO NAVIO     AP  252.531.560-03   \n",
       "4          Jeff Stephenson     73           ABAÍRA     BA     49668886542   \n",
       "...                    ...    ...              ...    ...             ...   \n",
       "9995  Rebekah Mitchell PhD     55          ABAIARA     CE  744.822.622-34   \n",
       "9996      Lisa Parrish Jr.     73         Brasília     DF     10683395190   \n",
       "9997      Michael Young MD     87   AFONSO CLÁUDIO     ES  538.223.638-04   \n",
       "9998      Kevin Watson DDS     82  ABADIA DE GOIÁS     GO     11632512408   \n",
       "9999  Mr. Joseph Wilson MD     50       AÇAILÂNDIA     MA  192.134.492-08   \n",
       "\n",
       "                    cnpj  \n",
       "0         06589184909526  \n",
       "1     25.673.336/2350-20  \n",
       "2         26543101702989  \n",
       "3     19.062.080/5100-98  \n",
       "4         97794530015384  \n",
       "...                  ...  \n",
       "9995  16.740.076/9329-75  \n",
       "9996      32246978843482  \n",
       "9997  86.601.303/7580-88  \n",
       "9998      08651414023648  \n",
       "9999  08.908.871/5161-91  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as  pd \n",
    "df = pd.read_csv(r\"C:\\Users\\fpurc\\OneDrive\\Documentos\\Python Scripts\\Git\\talent-data-analyst-lv4\\dados_cadastrais_fake.csv\",sep=\";\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ee4fb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nomes</th>\n",
       "      <th>idade</th>\n",
       "      <th>cidade</th>\n",
       "      <th>estado</th>\n",
       "      <th>cpf</th>\n",
       "      <th>cnpj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dennis Daniels</td>\n",
       "      <td>31</td>\n",
       "      <td>ACRELÂNDIA</td>\n",
       "      <td>AC</td>\n",
       "      <td>97566536800</td>\n",
       "      <td>06589184909526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leah Becker</td>\n",
       "      <td>42</td>\n",
       "      <td>ÁGUA BRANCA</td>\n",
       "      <td>AL</td>\n",
       "      <td>42526380707</td>\n",
       "      <td>25673336235020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sally Ford</td>\n",
       "      <td>18</td>\n",
       "      <td>ALVARÃES</td>\n",
       "      <td>AM</td>\n",
       "      <td>34647754103</td>\n",
       "      <td>26543101702989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Colleen Duncan</td>\n",
       "      <td>21</td>\n",
       "      <td>SERRA DO NAVIO</td>\n",
       "      <td>AP</td>\n",
       "      <td>25253156003</td>\n",
       "      <td>19062080510098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jeff Stephenson</td>\n",
       "      <td>73</td>\n",
       "      <td>ABAÍRA</td>\n",
       "      <td>BA</td>\n",
       "      <td>49668886542</td>\n",
       "      <td>97794530015384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Rebekah Mitchell PhD</td>\n",
       "      <td>55</td>\n",
       "      <td>ABAIARA</td>\n",
       "      <td>CE</td>\n",
       "      <td>74482262234</td>\n",
       "      <td>16740076932975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Lisa Parrish Jr.</td>\n",
       "      <td>73</td>\n",
       "      <td>Brasília</td>\n",
       "      <td>DF</td>\n",
       "      <td>10683395190</td>\n",
       "      <td>32246978843482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Michael Young MD</td>\n",
       "      <td>87</td>\n",
       "      <td>AFONSO CLÁUDIO</td>\n",
       "      <td>ES</td>\n",
       "      <td>53822363804</td>\n",
       "      <td>86601303758088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Kevin Watson DDS</td>\n",
       "      <td>82</td>\n",
       "      <td>ABADIA DE GOIÁS</td>\n",
       "      <td>GO</td>\n",
       "      <td>11632512408</td>\n",
       "      <td>08651414023648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Mr. Joseph Wilson MD</td>\n",
       "      <td>50</td>\n",
       "      <td>AÇAILÂNDIA</td>\n",
       "      <td>MA</td>\n",
       "      <td>19213449208</td>\n",
       "      <td>08908871516191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nomes  idade           cidade estado          cpf  \\\n",
       "0           Dennis Daniels     31       ACRELÂNDIA     AC  97566536800   \n",
       "1              Leah Becker     42      ÁGUA BRANCA     AL  42526380707   \n",
       "2               Sally Ford     18         ALVARÃES     AM  34647754103   \n",
       "3           Colleen Duncan     21   SERRA DO NAVIO     AP  25253156003   \n",
       "4          Jeff Stephenson     73           ABAÍRA     BA  49668886542   \n",
       "...                    ...    ...              ...    ...          ...   \n",
       "9995  Rebekah Mitchell PhD     55          ABAIARA     CE  74482262234   \n",
       "9996      Lisa Parrish Jr.     73         Brasília     DF  10683395190   \n",
       "9997      Michael Young MD     87   AFONSO CLÁUDIO     ES  53822363804   \n",
       "9998      Kevin Watson DDS     82  ABADIA DE GOIÁS     GO  11632512408   \n",
       "9999  Mr. Joseph Wilson MD     50       AÇAILÂNDIA     MA  19213449208   \n",
       "\n",
       "                cnpj  \n",
       "0     06589184909526  \n",
       "1     25673336235020  \n",
       "2     26543101702989  \n",
       "3     19062080510098  \n",
       "4     97794530015384  \n",
       "...              ...  \n",
       "9995  16740076932975  \n",
       "9996  32246978843482  \n",
       "9997  86601303758088  \n",
       "9998  08651414023648  \n",
       "9999  08908871516191  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cpf\"]=df[\"cpf\"].str.replace(\".\",\"\", regex =True ).replace(\"-\",\"\", regex =True  ).replace(\"/\",\"\", regex =True )\n",
    "df[\"cnpj\"]=df[\"cnpj\"].str.replace(\".\",\"\", regex =True ).replace(\"-\",\"\", regex =True  ).replace(\"/\",\"\", regex =True )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d18513a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cpf    10000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantidade_clientes = df[['cpf']]\n",
    "quantidade_clientes.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2497a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idade    53.7831\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media_idade = df[['idade']]\n",
    "media_idade.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2da9c40",
   "metadata": {},
   "source": [
    "**Problema 2**: Você deverá implementar um programa, para ler, tratar e particionar os dados.\n",
    "\n",
    "O arquivo fonte está disponível em `https://st-it-cloud-public.s3.amazonaws.com/people-v2_1E6.csv.gz`\n",
    "\n",
    "### Data Quality\n",
    "\n",
    "- Higienizar e homogenizar o formato da coluna `document`\n",
    "- Detectar através da coluna `document` se o registro é de uma Pessoa Física ou Pessoa Jurídica, adicionando uma coluna com essa informação\n",
    "- Higienizar e homogenizar o formato da coluna `birthDate`\n",
    "- Existem duas colunas nesse dataset que em alguns registros estão trocadas. Quais são essas colunas? \n",
    "- Corrigir os dados com as colunas trocadas\n",
    "- Além desses pontos, existem outras tratamentos para homogenizar esse dataset. Aplique todos que conseguir.\n",
    "\n",
    "### Agregação dos dados\n",
    "\n",
    "- Quais são as 5 PF que mais gastaram (`totalSpent`)? \n",
    "- Qual é o valor de gasto médio por estado (`state`)?\n",
    "- Qual é o valor de gasto médio por `jobArea`?\n",
    "- Qual é a PF que gastou menos (`totalSpent`)?\n",
    "- Quantos nomes e documentos repetidos existem nesse dataset?\n",
    "- Quantas linhas existem nesse dataset?\n",
    "\n",
    "### Particionamento de dados tratados com as regras descritas em `DATA QUALITY`\n",
    "\n",
    "- Particionar em arquivos PARQUET por estado (`state`)\n",
    "- Particionar em arquivos CSV por ano/mes/dia de nascimento (`birthDate`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4980cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "import urllib \n",
    "import datetime\n",
    "\n",
    "urllib.request.urlretrieve(\"https://st-it-cloud-public.s3.amazonaws.com/people-v2_1E6.csv.gz\",\"/tmp/teste.csv.gz\")\n",
    "%sh\n",
    "unzip /tmp/teste.csv.gz\n",
    "tail -n +2 teste.csv > temp.csv\n",
    "rm teste.csv\n",
    "\n",
    "df = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"header\",\"true\").load(\"dbfs:/tmp/teste.csv\")\n",
    "display(df)\n",
    "\n",
    "df.groupBy(\"state\").agg({\"totalSpent\":\"avg\"}).show()\n",
    "df.groupBy(\"jobArea\").agg({\"totalSpent\":\"avg\"}).show()\n",
    "\n",
    "df.withColumn('PF', f.sum('totalSpent')).sort('totalSpent').show()\n",
    "\n",
    "\n",
    "df.write.mode(\"overwrite\").partitionBy(\"state\").saveAsTable('teste', format='parquet')\n",
    "\n",
    "df.write.mode(\"overwrite\").partitionBy(year (\"birthDate\"),month (\"birthDate\"),day(\"birthDate\")).saveAsTable('teste', format='csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
